{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Classical Statistics: Hypothesis Testing**</font>\n",
    "\n",
    "**Statistical inference** is the process of making decisions based on observational data. In science, these decisions are often related to theoretical models.\n",
    "\n",
    "> **Theories** are potential **models** describing how nature works.\n",
    "\n",
    "> **Observations** are measurements of the properties of natural objects.\n",
    "\n",
    "To learn something new about the Universe we need to find ways to answer to questions such as:\n",
    "- Does our new theory agree with the data (hypothesis testing)?\n",
    "- What are the parameters of an existing theory (parameter estimation) calibrated on observational data?\n",
    "- Which theory is more probable (Model Comparison; we'll see that in a following session)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Hypothesis testing\n",
    "\n",
    "**Definition**\n",
    "\n",
    "Hypothesis testing is the process of testing an assumption regarding a parameter of a population, using a sample from the latter.\n",
    "\n",
    "**Testing the value of a parameter...***\n",
    "\n",
    "...means that we need to quantify the probability (density) of the parameter using a **statistic** calculated on the sample.\n",
    "\n",
    "## 1.1. Example: the sum of two independently and identically-distributed normal variables\n",
    "\n",
    "Let's assume that we have two data points with values $x$ and $y$, coming from the same normal distribution $N(\\mu,\\sigma)$, consequently:\n",
    "\n",
    "$$ P_X(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left[-\\frac{\\left(x-\\mu\\right)^2}{2\\sigma^2}\\right]$$\n",
    "\n",
    "$$ P_Y(y) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left[-\\frac{\\left(y-\\mu\\right)^2}{2\\sigma^2}\\right]$$\n",
    "\n",
    "**What is the probability density function of their sum, $z = x + y$ as a function of the data distribution parameters, $\\mu$ and $\\sigma$?**\n",
    "\n",
    "\n",
    "### Any thoughts?\n",
    "\n",
    "$$ P_Z(z) = Prob(x+y=z) = Prob(x=0, y=z) + Prob(x=0.1, y=z-0.1) + ... $$\n",
    "\n",
    "so...\n",
    "\n",
    "$$ P_Z(z) = \\int\\limits_{-\\infty}^{\\infty} P_X(x) P_Y(z-x) \\; dx \n",
    "=   \\int\\limits_{-\\infty}^{\\infty} \n",
    "    \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left[-\\frac{\\left(x-\\mu\\right)^2}{2\\sigma^2}\\right]\n",
    "    \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left[-\\frac{\\left(z-x-\\mu\\right)^2}{2\\sigma^2}\\right]\n",
    "     \\; dx \n",
    "$$\n",
    "\n",
    "(...after one page of math...)\n",
    "\n",
    "$$ P_Z(z) = \\frac{1}{\\sqrt{4\\pi \\sigma^2}} \\exp\\left[-\\frac{\\left(z-2\\mu\\right)^2}{4\\sigma^2}\\right] $$\n",
    "\n",
    "Does it seem familiar? If we use $\\sigma' = \\sqrt{2} \\sigma$...\n",
    "\n",
    "$$ P_Z(z) = \\frac{1}{\\sqrt{2\\pi \\sigma'^2}} \\exp\\left[-\\frac{\\left(z-2\\mu\\right)^2}{2\\sigma'^2}\\right] $$\n",
    "\n",
    "...so it's a normal distribution peaking at $2\\mu$ (naturally...), with a standard deviation $\\sqrt{2}$ times **higher** than that of the data distribution!\n",
    "\n",
    "Similarily, the mean value of the sample, since it's divided by 2, will have a mean value of $\\mu$, and a standard deviation $\\sqrt{2}$ times **lower** than that of the data distribution.\n",
    "\n",
    "### Using the resulting distribution\n",
    "\n",
    "Having quantified the probability density of the statistic, we can use the sum of two data points to test whether their sum is probable, or what is the probability of that being less or more than a specific value (e.g., 0).\n",
    "\n",
    "Let's assume that the underlying distribution of $x$ and $y$ is $\\mathcal{N}(3.5, 1)$... this is our **model** leading to the prediction that the sum will be distributed as $\\mathcal{N}(7, \\sqrt{2})$.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Select the number of samples to be drawn from the two distributions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the distribution of X and Y\n",
    "data_mean = 3.5\n",
    "data_std = 1.0\n",
    "data_dist = st.norm(data_mean, data_std)\n",
    "print(\"Two values from the data distribution:\", data_dist.rvs(size=2))\n",
    "\n",
    "# taking pairs of samples from the distribution, and summing them \n",
    "n_samples = ...\n",
    "sum_sample = data_dist.rvs(size=(n_samples, 2)).sum(axis=1)\n",
    "\n",
    "# the theoretically-expected distribution of the sum\n",
    "sum_dist = st.norm(2 * data_mean, np.sqrt(2.0) * data_std)\n",
    "\n",
    "# plotting\n",
    "xx = np.linspace(0.0, 13.0, 200)\n",
    "plt.figure()\n",
    "plt.plot(xx, data_dist.pdf(xx), \"k-\", label=\"Data distribution, $P_X(x)=P_Y(y)$\")\n",
    "plt.plot(xx, sum_dist.pdf(xx), \"r-\", label=\"Sum distribution, $P(z)$\")\n",
    "plt.hist(sum_sample, bins=\"fd\", density=True, alpha=0.5, label=\"Samples of $z$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: Knowing the distribution of X and Y, would observing a sum ($z$) equal to 4 surprise you?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "From the above experiment we see that there are samples of the sum close to $4$. However, most of the samples are at higher values... so it's a little bit surprising. We would expect the sum of 4 to arise if the distributions had smaller mean (rather than 3.5), or at least higher standard deviation (rather than 1). \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(0.0, 13.0, 200)\n",
    "plt.figure()\n",
    "plt.plot(xx, sum_dist.pdf(xx), \"r-\", label=\"Model expectation\")\n",
    "plt.axvline(4.0, color=\"k\", label=\"Observation\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(ymin=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Verifying a model for the mass of globular clusters (GC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. The data\n",
    "\n",
    "A research team has studied a sample of globular clusters and measured their masses. Let's load and plot their histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = np.genfromtxt(\"data/GC_MWG_masses.csv\")\n",
    "log_masses = np.log10(masses)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(log_masses, bins=20)\n",
    "plt.xlabel(\"$\\log M\\ [M_\\odot]$\")\n",
    "plt.ylabel(\"Number of globular clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. The theoretical model\n",
    "\n",
    "Globis & Clusterton (2022) used hydrodynamical galaxy simulations to model the formation of globular clusters (GC) in a galaxy like the Milky Way. They found that the masses of the synthetic GCs are described by a log-normal distribution. Namely, the logarithm of the masses are normally distributed:\n",
    "\n",
    "$$\\large \\log_{10} \\left(\\frac{M}{M_\\odot}\\right) \\sim \\mathcal{N}(5.5, 1) $$\n",
    "\n",
    "meaning that the GCs masses peak at $10^{5.5} M_\\odot \\simeq 3.2\\times 10^5 M_\\odot$ and the typical scatter is $1\\,\\mathrm{dex}$ (one order of magnitude).\n",
    "\n",
    "Let's see this the model along with the data...\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Select the appropriate distribution from scipy.stats: https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean = 5.5\n",
    "model_std = 1.0\n",
    "\n",
    "logm_for_plot = np.linspace(min(log_masses)-1, max(log_masses)+1, 100)\n",
    "model_prob_for_plot = st...(model_mean, model_std).pdf(logm_for_plot)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(log_masses, bins=20, density=True, label=\"Data\")\n",
    "plt.plot(logm_for_plot, model_prob_for_plot, \"r-\", lw=2, label=\"Model\")\n",
    "plt.xlabel(\"$\\log M\\ [M_\\odot]$\")\n",
    "plt.ylabel(\"Number of globular clusters\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Using the sample mean as a statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(log_masses)\n",
    "sample_std = np.std(log_masses)\n",
    "\n",
    "print(f\"MODEL:  Mean = {model_mean:.2f} | Std = {model_std:.2f}\")\n",
    "print(f\"SAMPLE: Mean = {sample_mean:.2f} | Std = {sample_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: is the sample mean close to the model's value?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "There is no right answer... it is subjective. Our goal here is to quantify this \"subjectiveness\"!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: does the standard deviation give a sense of how close the mean values are?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Not exactly. The standard deviation describes the scatter of the data. Itself does not say much about the deviation of the sample mean from the model's expectation.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Standard error of the mean\n",
    "\n",
    "Whether the mean values are close depends also on the sample size. The larger it is, the more accurate our estimate on the mean is, and we would expect it to converge to the mean of the underlying population (and that of the model if it is correct). \n",
    "\n",
    "For normally distributed data the **standard deviation of the mean** scales as:\n",
    "\n",
    "$$ \\large \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{N}} $$\n",
    "\n",
    "where $\\sigma$ is the population standard deviation and $N$ is the sample size.\n",
    "\n",
    "In most cases, the population deviation is unknown. For this reason, we use the same sample to estimate it, calculating the *sample standard deviation $s$*. The standard deviation of the sample mean is called **standard error on the mean**:\n",
    "\n",
    "$$ \\large s_{\\bar{x}} = \\frac{s}{\\sqrt{N}} $$\n",
    "\n",
    "The sample mean is considered to be normally distributed (see *Central Limit Theorem* below), and therefore we can calculate the number of standard errors the sample mean is away from the theoretical value, or the **sigmas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the standard error of the mean, and the difference in terms of sigmas from the model mean\n",
    "sample_sem = st.sem(log_masses)\n",
    "print(f\"Standard error of the mean = {sample_sem:.2f}\")\n",
    "print(f\"Sigma's of difference      : {(model_mean-sample_mean) / sample_sem:.2f}\")\n",
    "\n",
    "x_plot = np.linspace(sample_mean - 5 * sample_sem, sample_mean + 5 * sample_sem, 100)\n",
    "\n",
    "# the distribution of the sample mean (using the measured value and the standard error of the mean)\n",
    "mean_distribution = st.norm(sample_mean, sample_sem)\n",
    "\n",
    "# plotting\n",
    "y_plot = mean_distribution.pdf(x_plot)\n",
    "plt.figure()\n",
    "plt.plot(x_plot, y_plot, \"k-\", lw=2, label=\"$\\mathcal{N}$(mean, SEM)\")\n",
    "plt.axvline(sample_mean, ls=\"-\", color=\"b\", label=\"Sample mean\")\n",
    "plt.axvline(model_mean, ls=\"--\", lw=2, color=\"r\", label=\"Model mean\")\n",
    "for sigmas in [1, 2, 3]:\n",
    "    plt.axvspan(sample_mean - sigmas*sample_sem, sample_mean + sigmas*sample_sem, color=\"b\", alpha=0.1)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim(ymin=0.0)\n",
    "plt.xlabel(\"$\\log M\\ [M_\\odot]$\")\n",
    "plt.ylabel(\"PDF of the sample mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: is the means' difference small enough to accept the model?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Still subjective! But we are closer to quantifying this \"subjectiveness\"!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. When to reject a model...\n",
    "\n",
    "One might argue that if the theoretical mean is too extreme, either **too low** or **two high**, we should **reject the hypothesis that the model describes the data at hand**. \n",
    "\n",
    "Therefore we can calculate from the sample mean distribution what is the probability of such extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(sample_mean - 5 * sample_sem, sample_mean + 5 * sample_sem, 100)\n",
    "\n",
    "diff = abs(sample_mean - model_mean)\n",
    "xx_before = np.linspace(sample_mean - 5 * sample_sem, sample_mean - diff, 100)\n",
    "xx_after = np.linspace(sample_mean + diff, sample_mean + 5 * sample_sem, 100)\n",
    "\n",
    "mean_distribution = st.norm(sample_mean, sample_sem)\n",
    "y_plot = mean_distribution.pdf(x_plot)\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(xx_before, mean_distribution.pdf(xx_before), 0, color=\"r\", ec=\"none\", alpha=0.5, label=\"Area more extreme\")\n",
    "plt.fill_between(xx_after, mean_distribution.pdf(xx_after), 0, color=\"r\", ec=\"none\", alpha=0.5)\n",
    "plt.plot(x_plot, y_plot, \"k-\", lw=2, label=\"N(mean, sem)\")\n",
    "plt.axvline(sample_mean, ls=\"-\", color=\"b\", label=\"Sample mean\")\n",
    "plt.axvline(model_mean, ls=\"--\", lw=2, color=\"r\", label=\"Model mean\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim(ymin=0.0)\n",
    "plt.xlabel(\"$\\log M\\ [M_\\odot]$\")\n",
    "plt.ylabel(\"PDF of the sample mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution function is\n",
    "\n",
    "$$ \\large F(x) = \\int\\limits_{-\\infty}^{x} f(x') dx' $$\n",
    "\n",
    "The \"area more exteme\" is \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\large p   \n",
    "    &= \\large 1 - \\textrm{(area between)} = \\\\\n",
    "    &= 1 - \\int\\limits_{m-d}^{m+d} f(x') dx' = \\\\\n",
    "    &= 1 - \\left(\\int\\limits_{-\\infty}^{m+d} f(x')dx' - \\int\\limits_{\\infty}^{m-d} f(x')dx' \\right) = \\\\\n",
    "    &= \\large 1 - \\left[F(m+d) - F(m-d)\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which in our case is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_more_extreme = 1 - (mean_distribution.cdf(sample_mean+diff) - mean_distribution.cdf(sample_mean-diff))\n",
    "print(f\"Area more extreme, p = {area_more_extreme:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, there is $\\sim 7\\%$ probability, or **$p$-value** 0.07, to reject this model even if it is correct. *Can we risk it*? It is **our choice** to consider our \"threshold\" or **significance level**!\n",
    "\n",
    "If we had decided **before looking at the data** to use a 5% threshold, then our conclusion is that \n",
    "\n",
    "> *we do not reject the model, with a significance level of 5%\".*\n",
    "\n",
    "#### IMPORTANT: we didn't accept the model\n",
    "The analysis above does not validate the model!!! The only thing we verified is that **one property**, the mean value the data is not that different than what we would expect from the model. If it was, then we would have reasons to no believe the model. For example, if we had found $p=0.0001$ we would **reject the model** given the sample at hand.\n",
    "\n",
    "In Science, we can only disprove theories, never prove them.\n",
    "\n",
    "> \"It doesn't matter how beautiful your theory is, it doesn't matter how smart you are. If it doesn't agree with experiment, it's wrong.\" --- Richard Feynmann\n",
    "\n",
    "\n",
    "#### IMPORTANT: 100-7=93% is not the probablity for the hypothesis (or model) to be correct\n",
    "There are infinite other models under which the $p$-value above would be above our threshold. For example, $N(5.5, 0.101)$, $N(5.51, 0.1)$, ...\n",
    "\n",
    "> \"Whenever a theory appears to you as the only possible one, take this as a sign that you have neither understood the theory nor the problem which it was intended to solve.\" --- Karl Popper\n",
    "\n",
    "### Choosing the significance level\n",
    "\n",
    "There is no rule on what the significance level should be. Just that is should be decided before looking at the data, to avoid, **as humans, biasing our conclusions by relaxing our criteria for models we like, or making it harder for models we don't like!**\n",
    "\n",
    "In Astronomy, $2 + 2 \\simeq 5$, so we often use 0.5, 1 or 5%. In Nuclear physics and precision experiments often $10^{-7}$ or $10^{-10}$ are used!\n",
    "\n",
    "Since the $p$-value is connected to the number of sigmas in difference, often we refer to *sigmas* instead of a significance level. It is shorter to say, and it is easier to \"imagine\" it in plots with error bars and distributions. For example:\n",
    "\n",
    "| Sigmas | Probability (inside) | Probability (outside) |\n",
    "| --- | --- | --- |\n",
    "|  1 | 0.68 | 0.32 |\n",
    "|  2 | 0.954 | 0.046 |\n",
    "|  3 | 0.9973 | 0.0027 |\n",
    "|  5 | 0.9999994 | 0.0000006 |\n",
    "|  8 | 0.9999999999999987 | 0.0000000000000013\n",
    "\n",
    "\n",
    "> \"Creationists make it sound as though a 'theory' is something you dreamt up after being drunk all night.\" --- Isaac Asimov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: what does it mean to have a 10-sigma particle detection? Is it good that the significance level is very small?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Never judge before considering what is the null hypothesis! Previously, we checked a specific model, and therefore our null hypothesis was that the data agree with it (at least their mean).\n",
    "\n",
    "In particle detectors, the null hypothesis is usually: the signal was noise! There we test whether the data came about randomly. Rejecting that a signal is noise with significance level of 0.0000000000000000000015% is not bad at all!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Recap: the steps of *Hypothesis testing*\n",
    "\n",
    "> **Step 1**: We define the **null hypothesis** or the statement that we will test (a model or random outcome)\n",
    "\n",
    "> **Step 2**: We decide on a **significance level** - or what is the \"probability for being wrong in rejecting the null hypothesis\" that we are comfortable with?\n",
    "\n",
    "> **Step 3**: The **statistic** - a quantitiy that is computed on our *sample* assuming the *hypothesis is true*\n",
    "\n",
    "> **Step 4**: **$p$-value** OR **critical value**: compute the \"probability of being wrong\" or the value of the statistic based on which we will reject the hypothesis or not\n",
    "\n",
    "> **Step 5**: the decision!\n",
    "\n",
    "\n",
    "### Step 1. We define the null hypothesis\n",
    "\n",
    "> $H_0$: the mean value of the decimal logarithm of the masses of Milky Way GCs is consistent with the model\n",
    "\n",
    "### Step 2. We decide on a significance level\n",
    "\n",
    "This is the probability for rejecting the null hypothesis if it is true - the \"probability of being wrong\" if we reject the hypothesis at the end.\n",
    "\n",
    "> Let's take a significance level of $5\\%$, i.e. $a = 0.05$\n",
    "\n",
    "### Step 3. The statistic, $Z$-score\n",
    "\n",
    "#### Note: since we know it, we use the population standard deviation\n",
    "\n",
    "In order to decide whether the sample mean is consistent with the model's prediction, we must compute the **distribution of the sample mean given that the model is correct.**\n",
    "\n",
    "For $N$ observations $x_i$ the sample mean, $\\bar{x}$ is\n",
    "\n",
    "$$ \\bar{x} = \\frac{1}{N} \\sum\\limits_{i=1}^{N} x_i$$\n",
    "\n",
    "For normally distributed observations, $x_i \\sim \\mathcal{N}(\\mu, \\sigma)$, it is known that the sample mean is also normally distributed with mean equal to the population mean ($\\mu$) and standard deviation equal to the population standard deviation ($\\sigma$) devided by the square root of the size of the sample ($N$):\n",
    "\n",
    "$$ \\bar{x} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "...called *standard deviation of the mean*:\n",
    "\n",
    "$$ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{N}}$$\n",
    "\n",
    "Therefore the probability density function (PDF) of the sample mean is:\n",
    "\n",
    "$$f(\\bar{x}) = \\frac{1}{\\sqrt{2\\pi \\ \\sigma_{\\bar{x}}^2}} \\exp\\left[-\\frac{\\left(\\bar{x} - \\mu\\right)^2}{2 \\ \\sigma_{\\bar{x}}^2}\\right]$$\n",
    "\n",
    "Because of the ability to shift and scale the normal distribution, the quantity\n",
    "\n",
    "$$ Z = \\frac{\\bar{x} - \\mu}{\\sigma_{\\bar{x}}} $$\n",
    "\n",
    "follows the standard normal distribution (i.e. mean value $0$ and standard deviation $1$):\n",
    "\n",
    "$$ f(Z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}Z^2}$$\n",
    "\n",
    "Therefore, by just computing the $Z$ *score* of our sample, $z$, we can easily use tables for the normal distribution or code to quickly compute the probability at which $Z$ is below or above a specific value.\n",
    "\n",
    "We call this value $Z$ *statistic* or *score* and it used whenever the quantity we use to test the hypothesis is normally distributed.\n",
    "\n",
    "### Step 4. $p$-value and critical value(s) for the statistic\n",
    "\n",
    "\n",
    "<div><img src=\"images/two_tailed.png\" width=\"500\"/></div>\n",
    "\n",
    "\n",
    "Because of the null hypothesis, we must convert the statement \"*consistent with...*\" to a mathematical statement. In this example, we can consider that the sample mean is inconsistent with the model prediction if its significantly lower or higher (see *two tail test* instead of *one tail test*).\n",
    "\n",
    "Therefore, the Type I error is equal to probability that the $Z$ score deviates more than the absolute deviation of the score for the sample at hand:\n",
    "\n",
    "$$ p = P(Z > |z|) + P(Z < -|z|) $$\n",
    "\n",
    "Using the symmetry of normal distribution's PDF and the fact that $P({\\rm A}) + P({\\rm not\\ A}) = 1$, we arrive at\n",
    "\n",
    "$$ p = \\cdots = 2 \\left(1 - P\\left(Z < |z|\\right)\\right) = \\cdots = 2 P(Z < -|z|)$$\n",
    "\n",
    "or simply,\n",
    "\n",
    "$$ p = 2 \\Phi(-|z|) $$\n",
    "\n",
    "where $\\Phi(z)$ is the CDF of the standard normal distirbution.\n",
    "\n",
    "If we find $p < a = 0.05$ then we reject the null hypothesis.\n",
    "\n",
    "Alternatively, we can set **critical** values of the $Z$ score that correspond to the significance level of choice. As rejection should occur either for higher or lower values (two-tailed test), we find two critical values corresponding to $a/2$ probability:\n",
    "\n",
    "$$ Z_{\\rm crit,1} = \\Phi^{-1}\\left(\\frac{a}{2}\\right) = -1.96 $$\n",
    "\n",
    "$$ Z_{\\rm crit,2} = \\Phi^{-1}\\left(1 - \\frac{a}{2}\\right) = +1.96 $$\n",
    "\n",
    "Because of the symmetry of the normal distribution we could also compute a critical value for the absolute $Z$ score:\n",
    "\n",
    "$$ |Z|_{\\rm crit} = 1.96 $$\n",
    "\n",
    "This is equivalent to asking *how many **sigmas** away from the model prediction can the measured value be in order to reject the null hypotheis?* Astronomers are used to use the $\\sigma$ term: \"we reject the hypothesis on a $2\\sigma$ significance level!\"\n",
    "\n",
    "### Step 5. Decision\n",
    "\n",
    "Now that we defined all the steps, we can apply it on the data. In the following code, we compute the statistic and print the outcome based on $p$-value. Alternatively we can use the critical value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Examples of standard hypothesis tests\n",
    "\n",
    "## 3.1. $Z$-test \n",
    "\n",
    "Let's do the above with code, assuming we know the population standard deviation.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Apply the $z$-score and $p$-value formulae.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set alpha and compute the critical value(s)\n",
    "alpha = 0.05\n",
    "print(\"Significance level: {:7.3f}\".format(alpha))\n",
    "\n",
    "# compute the p-value and report the result\n",
    "sample_size = len(log_masses)\n",
    "sample_mean = np.mean(log_masses)\n",
    "stddev_mean = model_std / (sample_size ** 0.5)\n",
    "z_score = ...\n",
    "pvalue = ...\n",
    "\n",
    "print(\"Sample mean       : {:7.3f}\".format(sample_mean))\n",
    "print(\"Standard error    : {:7.3f}\".format(stddev_mean))\n",
    "print(\"Sample Z-score    : {:7.3f}\".format(z_score))\n",
    "print()\n",
    "print(\"p-value           : {:7.3g}\".format(pvalue))\n",
    "\n",
    "if pvalue <  alpha:\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")\n",
    "    \n",
    "print()\n",
    "\n",
    "# alternatively we could compute the critical value and base our outcome on it\n",
    "z_critical = abs(st.norm.ppf(alpha / 2.0))\n",
    "print(\"Critical values   : {:7.3f} and {:.3f}\".format(-z_critical, z_critical))\n",
    "if abs(z_score) > abs(z_critical):\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 $t$-test\n",
    "\n",
    "Above we used the theoretical value of $\\sigma$ to calculate the $Z$-score. We **assumed** that we know the standard deviation of the population! In most cases, we don't! Instead, we **estimate** the population parameter $\\sigma$ from the standard deviation in the sample $s$.\n",
    "\n",
    "*Caveat: we are using the same values to calculate the mean and the standard deviation - therefore there is one less degree of freedom in the statistic*:\n",
    "\n",
    "$$ \\large \\text{dof} = n - 1 $$\n",
    "\n",
    "> Is the mean value of a sample equal to the population mean (without knowing the population standard deviation)?\n",
    "\n",
    "The distribution of the sample mean now follows the Student's $t$-distribution.\n",
    "\n",
    "The corresponding statistic is\n",
    "\n",
    "$$ \\large t = \\frac{\\bar{x} - \\mu}{s / \\sqrt{n}} $$\n",
    "\n",
    "where $s$ is the sample standard deviation that takes the place of the population standard deviation in the $Z$-test we saw previously. The $t$-distribution is similar to the Gaussian but has 'heavier' tails when the sample size is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(sample_mean - 5 * sample_sem, sample_mean + 5 * sample_sem, 100)\n",
    "\n",
    "dof = len(log_masses) - 1   # the degrees of freedom\n",
    "Z_dist = st.norm(loc=sample_mean, scale=sample_sem)\n",
    "t_dist = st.t(dof, loc=sample_mean, scale=sample_sem)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for inlog, subplot_index in zip([False, True], [1, 2]):\n",
    "    plt.subplot(1, 2, subplot_index)\n",
    "    plt.plot(x_plot, t_dist.pdf(x_plot), \"r\", label=\"t-Student distribution\")\n",
    "    plt.plot(x_plot, Z_dist.pdf(x_plot), \"b\", label=\"Gaussian (Z) distribution\")\n",
    "    plt.xlabel(\"Sample mean\")\n",
    "    plt.ylabel(\"Probability density\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    if inlog:\n",
    "        plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "t_score = (sample_mean - model_mean) / sample_sem\n",
    "p_value = 2 * st.t(dof).cdf(-abs(t_score))  # implied that loc=0, scale=1\n",
    "\n",
    "print(\"Sample t-score    : {:7.3f}\".format(t_score))\n",
    "print(\"p-value           : {:7.3g}\".format(p_value))\n",
    "\n",
    "if pvalue <  alpha:\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")\n",
    "    \n",
    "print()\n",
    "\n",
    "# alternatively we could compute the critical value and base our outcome on it\n",
    "t_critical = abs(st.t(dof).ppf(alpha / 2.0))\n",
    "print(\"Critical values   : {:7.3f} and {:.3f}\".format(-t_critical, t_critical))\n",
    "if abs(t_score) > abs(t_critical):\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: how and why did $p$ and critical values change compared to the $Z$-test?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "The $p$-value is smaller because the sample standard deviation is smaller than the model one, leading to smaller $\\sigma/\\sqrt{N}$ too. Consequently, the difference between the means is statistically more significant compared to the $Z$-test!\n",
    "    \n",
    "For the same significance level, the critical values of the $t$-statistic have larger absolute values than the $Z$-statistic because the $t$-Student distribution is broader. In principle, larger differences between the means are tolerated when we don't know the standard deviation.\n",
    "\n",
    "The difference between the $Z$ and $t$ distributions in our example is small because we have a lot of data - it's way more important for really small samples. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Directly performing the $t$-student test\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Open the `scipy` documentation of the t-test function in https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html and complete the following code to perform the hypothesis testing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = st.ttest_1samp(..., ...)\n",
    "print(\"Statistic = {:.3g}\".format(statistic))\n",
    "print(\"p-value   = {:.3g}\".format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The Central Limit Theorem\n",
    "\n",
    "In the above example we assumed that the mean of the sample is normally-distributed, i.e. following the Gaussian distribution. This is often the case, at least with some approximation due to the **Central Limit Theorem**:\n",
    "\n",
    "> the sampling distribution of the sample mean approaches a normal distribution as the sample size gets larger, no matter what the shape of the population distribution.\n",
    "\n",
    "Let's take the *arcsine* distribution which does not look like a Gaussian at all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = st.arcsine()\n",
    "xx = np.linspace(0.0001, 1.0-0.0001, 1000)\n",
    "plt.figure()\n",
    "plt.plot(xx, distribution.pdf(xx))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![...](images/thats-just-not-normal.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the Central Limit Theorem by sampling the arcsine distribution using different sample sizes. We first plot how the first 3 samples and their means look like, and then we take a look at the distribution of those means after 10000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_of_iterations = 10000\n",
    "n_of_examples = 3\n",
    "hist_colors = plt.colormaps.get_cmap(\"turbo\")(np.linspace(0.2, 0.8, n_of_examples))\n",
    "sample_sizes = [1, 2, 3, 30, 1000]\n",
    "\n",
    "np.random.seed(31337)\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), constrained_layout=False)\n",
    "    plt.suptitle(f\"Sample size = {sample_size}\")   \n",
    "    ax1.set_title(f\"The first {n_of_examples} samples and their mean\")\n",
    "    ax2.set_title(f\"The distribution of the means of {n_of_iterations} samples\")\n",
    "    \n",
    "    sample_means = []\n",
    "    for iteration in range(n_of_iterations):\n",
    "        sample = distribution.rvs(size=sample_size)\n",
    "        sample_mean = np.mean(sample)\n",
    "        sample_means.append(sample_mean)\n",
    "        \n",
    "        if iteration < n_of_examples:\n",
    "            if sample_size > 1:\n",
    "                ax1.hist(sample, bins=10, density=True, histtype=\"step\",\n",
    "                         color=hist_colors[iteration], alpha=0.7, lw=1, label=f\"Iteration {iteration+1}\")\n",
    "            ax1.axvline(sample_mean, color=hist_colors[iteration], lw=3, alpha=0.7)\n",
    "\n",
    "    ax2.hist(sample_means, bins=50, histtype=\"step\", density=True, color=\"k\", lw=2)\n",
    "    xx = np.linspace(min(sample_means), max(sample_means), 200)\n",
    "    ax2.plot(xx, st.norm.pdf(xx, distribution.mean(), distribution.std() / sample_size**0.5), lw=2, color=\"r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Distribution tests\n",
    "\n",
    "## 5.1. Normality test\n",
    "\n",
    "Above we used our eyes to see the validity of the Central Limit Theorem. But our eyes, and plotting choices (e.g., bin sizes) might deceive us! Instead, we can test whether a sample follows a known distribution.\n",
    "\n",
    "In addition, in the hypothesis test, we assumed that the data are normally distributed. This is an expectation from the theory, and in could be tested independently of the parameters of the Gaussian distribution.\n",
    "\n",
    "When our analysis depends on the \"normality\" of a distribution, it is better the perform a hypothesis test for exactly that - a **noramlity test**!\n",
    "\n",
    "Here we use the **Shapiro-Wilk test for normality** (but it's not the only one out there) to test whether the log-masses of the GCs are following the normal distribution.\n",
    "\n",
    "We **always have to ask which one is the null hypothesis test when using them as a black box**. For Shapiro-Wilk is:\n",
    "\n",
    ">  $H_0$: the sample came from a normally distributed population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.shapiro(log_masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Arbitrary distribution test: the K-S test\n",
    "\n",
    "Note that a normality test, is very specific to the distribution we check against (Gaussian), but not its parameters. To check for agreement with any distribution, the **Kolmogorov-Smirnov** test can be used.\n",
    "\n",
    "> $H_0$: the sample is drawn from the reference distribution\n",
    "\n",
    "The test is measuring the maximum distance between two cumulative distribution functions (from the sample and a model/another sample), which is called $D$ statistic. Depending on the number of samples, the $D$ statistics corresponds to a $p$-value. Let's see how it looks for our example, against the model distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(log_masses)-1, max(log_masses)+1, 1000)\n",
    "xx = (bins[1:] + bins[:-1]) / 2.0\n",
    "\n",
    "model_cdf = st.norm.cdf(xx, loc=model_mean, scale=model_std)\n",
    "plt.figure()\n",
    "sample_cdf, _, _ = plt.hist(log_masses, bins=bins, density=True, cumulative=1, \n",
    "                            histtype=\"step\", label=\"Sample CDF\")\n",
    "\n",
    "# where is the maximum difference between the model and sample CDFs?\n",
    "where_max_d = np.argmax(np.abs(model_cdf - sample_cdf))\n",
    "\n",
    "# find the height of the CDFs at their furthest point\n",
    "D1, D2 = model_cdf[where_max_d], sample_cdf[where_max_d]\n",
    "\n",
    "# the maximum difference\n",
    "D = abs(D1 - D2)\n",
    "\n",
    "plt.plot(xx, model_cdf, label=\"Model CDF\")\n",
    "plt.plot([xx[where_max_d]]*2, [D1, D2], \"k:\", label=\"D={:.4g}\".format(D))\n",
    "plt.xlabel(\"$\\log M\\ [M_\\odot]$\")\n",
    "plt.ylabel(\"Cumulative distribution function\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2a: Perform a Kolmogorov-Smirnoff test\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Test whether the log masses of the GCs follow the model's distribution. Use https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html to find out the syntax of the `scipy` function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the K-S test\n",
    "model_distribution = st.norm(model_mean, model_std)\n",
    "st.kstest(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: Why do we get a different $p$-value with the K-S test, compared to the normality test?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "It's not that one method is incorrect! The questions are different, i.e., we tested different hypotheses!\n",
    "\n",
    "With the Shapiro-Wilk test we tested if the data are normally distributed, whatever the mean and standard deviation. With the K-S test we tested if the data follow a very specific normal distribution with a defined mean and standard deviation.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2b: Testing a distribution with its own sample\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Obviously, if we compare a sample's distribution with the true distribution, we expect (most of the times) agreement! Pick a sample size and run the K-S test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = model_distribution.rvs(size=...)\n",
    "st.ks_1samp(new_sample, model_distribution.cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2c: Comparing two samples\n",
    "\n",
    "We can also use the K-S test to compare two different samples: are they coming from the same distribution?\n",
    "\n",
    "Let's spicy things up and construct two distributions that are slightly different. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Select different sample sizes for each distribution. When does the test result in rejecting the hypothesis?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution1 = st.norm(0.0, 1.0)\n",
    "distribution2 = st.norm(0.1, 0.98)\n",
    "sample1 = distribution1.rvs(size=...)\n",
    "sample2 = distribution2.rvs(size=...)\n",
    "\n",
    "xmin_for_plotting = min(distribution1.ppf(0.001), distribution2.ppf(0.001))\n",
    "xmax_for_plotting = max(distribution1.ppf(0.999), distribution2.ppf(0.999))\n",
    "xx = np.linspace(xmin_for_plotting, xmax_for_plotting, 1000)\n",
    "plt.figure()\n",
    "plt.plot(xx, distribution1.pdf(xx), color=\"b\", label=\"Distribution 1\")\n",
    "plt.plot(xx, distribution2.pdf(xx), color=\"g\", label=\"Distribution 2\")\n",
    "plt.hist(sample1, bins=\"fd\", histtype=\"step\", color=\"b\", alpha=0.5, density=True, label=\"Sample 1\")\n",
    "plt.hist(sample2, bins=\"fd\", histtype=\"step\", color=\"g\", alpha=0.5, density=True, label=\"Sample 2\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "st.ks_2samp(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: In the last exercise the distributions are different. How do you explain the effect of sample size?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "With the hypothesis tests, we never \"accept\" the null hypothesis (here, agreement). It was never wrong. We were just failing to reject the hypothesis because of lack of data!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Non-parametric hypothesis testing\n",
    "\n",
    "What if there is no standard hypothesis test designed for our case? Or, what if the distribution of the statistic is hard to construct analytically?\n",
    "\n",
    "No worries: If we can simulate data, we can use sampling methods to explore the expected values of the statistic we chose!\n",
    "\n",
    "## 6.1. Example: Is the maximum globular mass consistent to the expectation from the model?\n",
    "\n",
    "<font size=3><u>**In-class discussion: Why would we use the statistic of `max` in astronomical data? Or `min`?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "    It's typically difficult to measure faint objects: often we may observe only a few samples of the high-end of the distribution.\n",
    "    On the other hand, there are situations where the minimum is easier to be observed; for example, it's easier to detect exoplanets or binary stars with small orbital periods. \n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis testing relies on the knowledge of the distribution of statistic, under the assumption that the **null hypothesis** holds. And here the hypothesis is that the sample follows the theoretical model.\n",
    "\n",
    "The statistic can be anything, but note that the size of the sample is almost always important. The maximum log mass in our sample is $\\sim 6.8$. Obviously, the larger the sample, the higher the chances to find higher maxima, so the sample size, 81, is important!\n",
    "\n",
    "So the question we need to answer is,\n",
    "\n",
    "> Under the null hypothesis that the log mass of GCs follows a normal distribution $N(5.5, 1)$, is the maximum of 81 samples equal to 6.8?\n",
    "\n",
    "### Simulating data\n",
    "Since the **null hypothesis** is assumed to be correct, we need to create a sample of 81 GCs in a *parallel Universe* where the model holds (the log mass distribution).\n",
    "\n",
    "### Computing the statistic\n",
    "\n",
    "Using the simulated data, we can calculate any statistic following the same procedure as in the observational data. Here, it's simply taking the `max`.\n",
    "\n",
    "### Constructing the \"empirical PDF\" of the statistic\n",
    "\n",
    "We do the above multiple times (the more the better) to empirically construct the distribution of the statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT #############################################################\n",
    "\n",
    "# 1. Defining the null hypothesis (or the model)\n",
    "model_distribution = st.norm(model_mean, model_std)\n",
    "\n",
    "# 2. Defining the statistic (applied to observations, and simulated data)\n",
    "def the_statistic(sample):\n",
    "    return np.max(sample)\n",
    "\n",
    "# 3. The number of iterations (simulations): the higher, the better\n",
    "n_iterations = 10000\n",
    "\n",
    "# 4. The size of the sample in each iteration (equal to the observed sample's size)\n",
    "sample_size = len(log_masses)\n",
    "\n",
    "# 5. Construct the statistic's distribution (following the model)\n",
    "max_samples = np.array([the_statistic(model_distribution.rvs(size=sample_size)) for _ in range(n_iterations)])\n",
    "\n",
    "# NOTE: we still haven't used the statistic's value in the sample!\n",
    "\n",
    "\n",
    "# MESAURING THE P-VALUE ##################################################\n",
    "\n",
    "# The observed maximum\n",
    "sample_max = the_statistic(log_masses)\n",
    "\n",
    "# Measuring how extreme the observed maximum is w.r.t. the model's distribution of the statistic\n",
    "expected_max = np.mean(max_samples)\n",
    "dist_from_expected_max = abs(expected_max - sample_max)\n",
    "p_value = np.mean((max_samples < expected_max - dist_from_expected_max) | (max_samples > expected_max + dist_from_expected_max))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"p-value = {p_value:.4f}\")\n",
    "plt.hist(max_samples, bins=\"fd\", label=\"Distribution of maximum\")\n",
    "plt.axvline(expected_max, color=\"k\", label=\"Expected max\")\n",
    "plt.axvline(sample_max, color=\"r\", label=\"Sample's max\")\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.axvspan(xmin, expected_max-dist_from_expected_max, color=\"r\", alpha=0.2, label=\"p-value region\")\n",
    "plt.axvspan(expected_max+dist_from_expected_max, xmax, color=\"r\", alpha=0.2)\n",
    "plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2. One-tail vs. two-tail tests\n",
    "\n",
    "Notice that in all the above tests, we care about whether a specific value is extreme with respect to the mean value, without caring if it's less or greater!\n",
    "But is this always the case?\n",
    "\n",
    "## Example: detecting a source\n",
    "\n",
    "In astronomical observations, we often aim to detect sources... in the presence of background noise!\n",
    "\n",
    "Let's assume that in a arcsec$^2$ region in our observed image, the average background counts is 10.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_background_counts = 10.3\n",
    "counts = np.arange(0, np.ceil(expected_background_counts*5))\n",
    "\n",
    "bkg_dist = st.poisson(expected_background_counts)\n",
    "pmf = bkg_dist.pmf(counts)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(counts, pmf, \"ko\", label=\"Counts from background\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: Would you say there is a source if 30 counts where detected? What is the null hypothesis?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "It seems like there is a source. The null hypothesis is that the detected counts are coming from the background.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: Would you say there is a source if 0 counts where detected?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "It's well below the expected background. This cannot imply there is a source because sources do not \"negate\" the background! Therefore it seems like the background was \"lazy\"! We can only infer the existence of a source if it exceeds the background by a lot!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_counts = 30\n",
    "significance_level = 0.001\n",
    "\n",
    "p_value = 1.0 - bkg_dist.cdf(detected_counts)\n",
    "print(f\"p-value corresponding to more than {detected_counts} counts: {p_value:.4g}\")\n",
    "\n",
    "critical_value = bkg_dist.ppf(1.0 - significance_level)\n",
    "print(f\"Critical value for rejecting null hypothesis: {critical_value:.4g}\")\n",
    "\n",
    "# we can use either the p-value or the critical value here...\n",
    "print(f\"With significance level {significance_level:.4g} we\", \"reject\" if p_value < significance_level else \"cannot reject\", \"the null hypothesis (that this is from background noise).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-astrostat24] *",
   "language": "python",
   "name": "conda-env-miniconda3-astrostat24-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
