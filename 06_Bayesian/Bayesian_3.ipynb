{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b33d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb415e",
   "metadata": {},
   "source": [
    "\n",
    "$$\\Large P(\\textrm{hypothesis} | \\textrm{data}, I) = \\dfrac{P(\\textrm{data} | \\textrm{hypothesis}, I) P(\\textrm{hypothesis} | I)}{P(\\textrm{data} | I)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c17d8b",
   "metadata": {},
   "source": [
    "# 1. Fitting a line\n",
    "\n",
    "In astronomy, a lot of information about the physical and emission properties of astronomical objects is accessed through spectroscopic measurements, i.e., the emission intensity as a function of wavelength/frequency. Interesting spectral features are emission or absorption lines. Naturally, the lines are not... lines, but narrow peaks! A true line is impossible due to quantum effects, but in addition, local/extended effects tend to \"broaden\" or alter the shape of spectal lines (e.g., thermal doppler, pressure, rotation of object, \n",
    "\n",
    "$$\\large \n",
    "y(x) = \\dfrac{A}{1 + \\left(\\dfrac{x - x_0}{w}\\right)^2}           \\qquad \\text{(Lorentzian or Cauchy model)}\n",
    "$$\n",
    "\n",
    "$$\\large \n",
    "y(x) = A \\exp{\\left[-\\frac{\\left(x - x_0\\right)^2}{2 w^2}\\right]} \\qquad \\text{(Gaussian or Normal model)}\n",
    "$$\n",
    "\n",
    "\n",
    "where \n",
    "* $A$ is the amplitude (notice that $y(x_0) = A$ in both cases), \n",
    "* $x_0$ is the location parameter (the center of the line), and\n",
    "* $w$ is the \"spread\" or width of the line.\n",
    "\n",
    "\n",
    "> Notice that here we use the word Cauchy and Gaussian to refer to non-linear models rather than distributions. Our data follows the shape of the PDFs of these distributions, not the distributions themselves!\n",
    "\n",
    "\n",
    "Now, let's assume we have measured the intensitities $y_i$ at given (unitless) wavelengths $x_i$, and that the errors $e_i$ are normally distributed with standard deviation $\\sigma$:\n",
    "\n",
    "$$\\large y_i = y(x_i) + \\epsilon_i, \\qquad \\epsilon_i \\sim \\text{Norm}(0, \\sigma)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e30dd12",
   "metadata": {},
   "source": [
    "## 1.1. The data from an unknown distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2024)\n",
    "\n",
    "def make_data(x, model_dist, amplitude, location, width, error_scale=0.0):\n",
    "    \"\"\"Make a spectral line following the PDF of a given distribution.\n",
    "    \n",
    "    x           : the wavelength\n",
    "    model_dist  : the distribution of which the PDF will be used\n",
    "    amplitude   : the maximum height of the spectral line\n",
    "    location    : the center of the spectral line\n",
    "    width       : the width of the spectral line\n",
    "    error_scale : the standard deviation of the observational uncertainties\n",
    "    \n",
    "    NOTE: use default `error_scale` (0.0) to get a model instead of an observational sample.\n",
    "    \n",
    "    \"\"\"\n",
    "    distribution = model_dist(loc=location, scale=width)\n",
    "    y = distribution.pdf(x)\n",
    "    y = amplitude * y / np.max(y)\n",
    "    if error_scale > 0:\n",
    "        y = np.random.normal(y, scale=error_scale)\n",
    "    y_err = np.ones_like(y) * error_scale\n",
    "    return y, y_err\n",
    "\n",
    "\n",
    "n_data = 20\n",
    "\n",
    "# two potential distributions\n",
    "model_distributions = [st.cauchy, st.norm]\n",
    "model_distributions_names = [\"Cauchy\", \"Normal\"]\n",
    "\n",
    "# select pseudo-randomly the true distribution\n",
    "random_index = 2023 % 17 % 2\n",
    "true_model_distribution = model_distributions[random_index]\n",
    "true_model_distribution_name = model_distributions_names[random_index]\n",
    "\n",
    "# Permitted ranges for the parameters (because we processed the data and we have some intuition)\n",
    "MIN_AMPLITUDE = 0.9\n",
    "MAX_AMPLITUDE = 1.1\n",
    "MIN_LOCATION = 0.45\n",
    "MAX_LOCATION = 0.55\n",
    "MIN_WIDTH = 0.05\n",
    "MAX_WIDTH = 0.15\n",
    "\n",
    "# Select the true parameters (these are supposed to be hidden from us)\n",
    "true_amplitude = np.random.uniform(MIN_AMPLITUDE, MAX_AMPLITUDE)\n",
    "true_location = np.random.uniform(MIN_LOCATION, MAX_LOCATION)\n",
    "true_width = np.random.uniform(MIN_WIDTH, MAX_WIDTH)\n",
    "\n",
    "# Make the new data according to the true model\n",
    "x_data = np.linspace(0.0, 1.0, n_data) + np.random.uniform(-0.5/n_data, 0.5/n_data, size=n_data)\n",
    "y_data, e_data = make_data(x_data, true_model_distribution, amplitude=true_amplitude, location=true_location, width=true_width, error_scale=0.1)\n",
    "\n",
    "# Plot them!\n",
    "plt.figure()\n",
    "plt.errorbar(x_data, y_data, yerr=e_data, fmt=\"k.\", capsize=4, label=\"Data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61dfafa",
   "metadata": {},
   "source": [
    "## 1.2. Overplotting two potential models using fiducial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e47d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the midpoints of the permitted ranges of the parameters\n",
    "fiducial_amplitude = (MIN_AMPLITUDE + MAX_AMPLITUDE) / 2.0\n",
    "fiducial_location = (MIN_LOCATION + MAX_LOCATION) / 2.0\n",
    "fiducial_width = (MIN_WIDTH + MAX_WIDTH) / 2.0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_data, y_data, \"ks\", mfc=\"none\", label=\"Data\")\n",
    "\n",
    "for model_distribution in model_distributions:\n",
    "    x_plot = np.linspace(0, 1, 100)\n",
    "    y_plot, _ = make_data(x_plot, \n",
    "                          model_distribution,            # try this model\n",
    "                          amplitude=fiducial_amplitude,  # fiducial...\n",
    "                          location=fiducial_location,    # ...parameters...\n",
    "                          width=fiducial_width,          # ...from ranges\n",
    "                          error_scale=0.0                # the prediction does not have uncertainty\n",
    "                         )\n",
    "    plt.plot(x_plot, y_plot, label=model_distribution.name)\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fd307",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: The plotted models use fiducial values for the parameters. However to you think one fits best than the other?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "It's purely subjective at this point!\n",
    "<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43b5a6",
   "metadata": {},
   "source": [
    "# 1.3. Defining the prior, likelihood and posterior assuming Gaussian profile...\n",
    "\n",
    "**Reminder**: we operate in log-space (log-prior, log-likelihood, log-posterion) for numerical reasons.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Complete the functions. Hint: the `make_data` function can be used to get model predictions as well! \n",
    "    \n",
    "**Warning**: the function returns two things!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3667fc",
   "metadata": {},
   "source": [
    "**(Reminder) From cell above:**\n",
    "```python\n",
    "# Permitted ranges for the parameters (because we processed the data and we have some intuition)\n",
    "MIN_AMPLITUDE = 0.9\n",
    "MAX_AMPLITUDE = 1.1\n",
    "MIN_LOCATION = 0.45\n",
    "MAX_LOCATION = 0.55\n",
    "MIN_WIDTH = 0.05\n",
    "MAX_WIDTH = 0.15\n",
    "\n",
    "# Our observed data\n",
    "x_data = np.linspace(0.0, 1.0, n_data) + np.random.uniform(-0.5/n_data, 0.5/n_data, size=n_data)\n",
    "y_data, e_data = make_data(x_data, true_model_distribution, amplitude=true_amplitude, location=true_location, width=true_width, error_scale=0.1)\n",
    "```\n",
    "\n",
    "**(Reminder): From MLE notebook:**\n",
    "\n",
    "Under the assumption of Gaussian uncertainties and independence of data,\n",
    "$$\\large\n",
    "\\ln L = \\text{constant} - \\frac{1}{2} \\sum_{i=1}^{N} {\\dfrac{(y_i-f(x_i))^2}{\\sigma_i^2}} = \\text{constant} - \\frac{\\chi^2}{2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037da758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_prior(amplitude, location, width):\n",
    "    ...\n",
    "\n",
    "def ln_likelihood_norm(amplitude, location, width):\n",
    "    ...\n",
    "\n",
    "def ln_posterior_norm(amplitude, location, width):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a53fa",
   "metadata": {},
   "source": [
    "# 1.4. Maximizing the posterior\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Tasks:**\n",
    "1. Define the function to be minimized in order to maximize the posterior.\n",
    "2. Choose appropriate starting values for the minimization routine.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_ln_posterior_norm(theta):\n",
    "    amplitude, location, width = theta\n",
    "    return ...\n",
    "\n",
    "min_result_norm = minimize(neg_ln_posterior_norm, x0=[..., ..., ...], method='Nelder-Mead')\n",
    "est_amplitude, est_location, est_width = min_result_norm.x\n",
    "\n",
    "\n",
    "print(min_result_norm)\n",
    "print()\n",
    "print(\"| PARAMETER  |  ESTIMATION  |  TRUTH  |\")\n",
    "print(f\"| amplitude  | {est_amplitude:11.3f}  | {true_amplitude:6.3f}  |\")\n",
    "print(f\"| location   | {est_location:11.3f}  | {true_location:6.3f}  |\")\n",
    "print(f\"| width      | {est_width:11.3f}  | {true_width:6.3f}  |\")\n",
    "print()\n",
    "print(\"At best-fitting values...\")\n",
    "lnL_norm = ln_likelihood_norm(*min_result_norm.x)\n",
    "lnP_norm = ln_posterior_norm(*min_result_norm.x)\n",
    "print(f\"  * log-prior      : {ln_prior(*min_result_norm.x):.6f}\")\n",
    "print(f\"  * log-likelihood : {lnL_norm:.6f}\")\n",
    "print(f\"  * log-posterior  : {lnP_norm:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9a850",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: The fit was successful and we got parameters close to the truth. Is the Gaussian model validated?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "As in hypothesis testing, the model is assumed to be true. The fitting process does not validate the model. The value of the log-posterior does not convey any information regarding the validity of the model.\n",
    "<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984de78",
   "metadata": {},
   "source": [
    "## 1.5. Repeating using a Cauchy profile\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Tasks:**  Do the same steps for the Cauchy profile.\n",
    "    \n",
    "1. Complete the functions.\n",
    "2. Choose appropriate starting values for the minimization routine.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_likelihood_cauchy(amplitude, location, width):\n",
    "    ...\n",
    "\n",
    "def ln_posterior_cauchy(amplitude, location, width):\n",
    "    ...\n",
    "\n",
    "def neg_ln_posterior_cauchy(theta):\n",
    "    amplitude, location, width = theta\n",
    "    return ...\n",
    "\n",
    "min_result_cauchy = minimize(neg_ln_posterior_cauchy, x0=[..., ..., ...], method='Nelder-Mead')\n",
    "est_amplitude, est_location, est_width = min_result_cauchy.x\n",
    "\n",
    "print(min_result_cauchy)\n",
    "print()\n",
    "print(\"| PARAMETER  |  ESTIMATION  |  TRUTH  |\")\n",
    "print(f\"| amplitude  | {est_amplitude:11.3f}  | {true_amplitude:6.3f}  |\")\n",
    "print(f\"| location   | {est_location:11.3f}  | {true_location:6.3f}  |\")\n",
    "print(f\"| width      | {est_width:11.3f}  | {true_width:6.3f}  |\")\n",
    "print()\n",
    "print(\"At best-fitting values...\")\n",
    "lnL_cauchy = ln_likelihood_cauchy(*min_result_cauchy.x)\n",
    "lnP_cauchy = ln_posterior_cauchy(*min_result_cauchy.x)\n",
    "print(f\"  * log-prior      : {ln_prior(*min_result_cauchy.x):.6f}\")\n",
    "print(f\"  * log-likelihood : {lnL_cauchy:.6f}\")\n",
    "print(f\"  * log-posterior  : {lnP_cauchy:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036fa27",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: What can you infer from the comparison between the resulting when assuming normal vs. Cauchy?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "The parameters are in both cases close to the truth. Whether they are closer or not, in practice, we cannot use in real data because we don't know the truth!\n",
    "The likelihood and posterior is, however, different! Maybe we can use this?\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c7345c",
   "metadata": {},
   "source": [
    "# 2. Selecting models\n",
    "\n",
    "If we don't know the correct model for the data ($D$), then we have a model selection problem. We should come up with all potential models, or at least those expected from our prior experience with the data and the underlying mechanisms decribing them.\n",
    "\n",
    "In the case above we have the Normal and Cuachy model. Let's name them A and B respectively. We can compare the posteriors by taking their ratio:\n",
    "\n",
    "Posterior odds: $ \\dfrac{P(A|D)}{P(B|D)} $\n",
    "\n",
    "Using the Bayes rule we can express it in the following way:\n",
    "\n",
    "$$\\Large \\dfrac{P(A|D)}{P(B|D)} = \\dfrac{P(D|A)P(A) / P(D)}{P(D|B)P(B) / P(D)} = \\dfrac{P(D|A)P(A)}{P(D|B)P(B)}$$\n",
    "\n",
    "## 2.1. Likelihood ratio (prior-independent)\n",
    "\n",
    "As we can see, the results depend on our prior belief on the models. In many cases, we want to be completely fair, and therefore we assign equal prior to both of them, resulting in:\n",
    "\n",
    "$$ \\Large \\dfrac{P(D|A)}{P(D|B)} $$\n",
    "\n",
    "which is also used by **frequentists** under the name **likelihood ratio statistic**:\n",
    "\n",
    "$$ \\Large \\mathrm{LR}_{AB} = \\dfrac{L_A}{L_B} = e^{l_A - l_B} $$\n",
    "\n",
    "where the $l_A$ and $l_B$ are the log-likelihoods for convenience.\n",
    "\n",
    "> The larger the likelihood ratio, the more preferred Model A is with respect to Model B\n",
    "\n",
    "\n",
    "### Connection to comparison of $\\chi^2$ values\n",
    "\n",
    "Under the assumption of Gaussian errors, then our log-likelihood is: *(some constant)* $-\\chi^2$. Therefore, if we compute the $\\chi^2$ values of the best fitting parameters for our models A and B, then the likelihood ratio is:\n",
    "\n",
    "$$ \\Large \\mathrm{LR}_{AB} = e^{l_A - l_B} = e^{-\\chi_A^2+\\chi_B^2} $$\n",
    "\n",
    "so the model with smallest $\\chi^2$ is preferred.\n",
    "\n",
    "## 2.2. Taking into account the flexibility of the models\n",
    "\n",
    "In classical statistics, we don't compare $\\chi^2$ values, but the **reduced-$\\chi^2$** which is divided by the degrees of freedom (number of data point - number of model parameters) to penalize complicated models that can fit the data easily without necessarily being the true model. In Bayesian statistics there are varous tools:\n",
    "\n",
    "### The Akaike Information Criterion\n",
    "\n",
    "If we use a model to represent the data, we lose information! There is structure/noise/etc. that we have lost! AIC measures the amount of information that is lost, **relative to another model**.\n",
    "\n",
    "A good model \"extracts\" or \"represents\" most of the information from a system, or... it maximizes its entropy! The AIC is the application of the Second Law of Thermodynamics on statistics using information theory (cf. *Shannon's information entropy*).\n",
    "\n",
    "$$\\large\n",
    "\\text{AIC} = 2k - 2\\ln L\n",
    "$$\n",
    "\n",
    "where $k$ is the number of parameters of the model (if we had to estimate them from the data), and $L$ is the likelihood of the data according to the model.\n",
    "\n",
    "\n",
    "> The larger the AIC, the more information is lost, so the worst for our model!\n",
    "\n",
    "\n",
    "\n",
    "#### k is a penalty term\n",
    "\n",
    "Using a 100-degree polynomial or a k-nearest neighbor interpolator, we could capture all trends in the data. However, this is just shifting all the information into parameters - it's not fair to compare something like that against a linear model!\n",
    "\n",
    "### The Bayesian Information Criterion\n",
    "\n",
    "$$\\large\n",
    "\\text{BIC} = k \\ln N - 2\\ln L\n",
    "$$\n",
    "\n",
    "where $N$ is the size of the sample used to calculate the likelihood.\n",
    "\n",
    "AIC vs. BIC: it's complicated...\n",
    "\n",
    "> As in AIC, the larger the BIC, the more information is lost, so the worst for our model!\n",
    "\n",
    "\n",
    "\n",
    "### Bayesian Factors\n",
    "\n",
    "Like the likelihood ratio, but here, the likelihoods are not that of the best fit. It takes into account all possible values for the parameters (which can be different in each model), $\\theta$!\n",
    "\n",
    "$$\\large\n",
    "\\text{K} = \\dfrac{P(D|A)}{P(D|B)} = \\dfrac{\\int P(\\theta_A) P(D|\\theta_A, A) d\\theta} {\\int P(\\theta_B) P(D|\\theta_B, B) d\\theta}\n",
    "$$\n",
    "\n",
    "> As in the likelihood ratio, the larger the value, the better for Model A compared to Model B!\n",
    "\n",
    "\n",
    "### The Jeffreys' scale\n",
    "\n",
    "| Bayes Factor | Strength of evidence |\n",
    "| --- | --- |\n",
    "|  1 - 3.2 | Not worth more than a bare mention |\n",
    "|  3.2 - 10 | Substantial |\n",
    "|  10 - 100 | Strong |\n",
    "|  >100 | Decisive |\n",
    "\n",
    "\n",
    "## 2.3. Let's compare the AICs, BICs\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Calculate the AICs and BICs, and decide which model *won*!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d307ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_norm = ...\n",
    "AIC_cauchy = ...\n",
    "\n",
    "BIC_norm = ...\n",
    "BIC_cauchy = ...\n",
    "\n",
    "print(\"AIC (norm, cauchy):\", AIC_norm, AIC_cauchy)\n",
    "print(\"BIC (norm, cauchy):\", BIC_norm, BIC_cauchy)\n",
    "print(\"Posterior ratio (norm / cauchy)  =\", np.exp(lnP_norm - lnP_cauchy))\n",
    "print(\"Posterior ratio (cauchy / norm)  =\", np.exp(lnP_cauchy - lnP_norm))\n",
    "\n",
    "print(\"And the truth is.... (drum roll)... The\", true_model_distribution_name, \"distribution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2f565",
   "metadata": {},
   "source": [
    "# 3. Helping model selection\n",
    "\n",
    "<font size=3><u>**In-class discussion: What could you change to increase the contrast between the models??**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Since the models cannot change, data have to. Only if we get more data we can be more confident in selecting models. Increase the size of the synthetic data and try again!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab8db5",
   "metadata": {},
   "source": [
    "# 4. Computing the Bayes Factor\n",
    "\n",
    "Bayes Factors are agnostic about the location of the posterior maximum! They use the *marginal likelihood* or the *evidence*: the integral of the likelihood over all possible values of the parameters.\n",
    "\n",
    "This makes them hard to compute, especially in complex, multi-dimensional parameter spaces. Thankfully, there are techniques like **Monte Carlo integration** that can help us.\n",
    "\n",
    "Essentially, instead of integrating a function over $x$, we use the sum of uniform samples of $x$:\n",
    "\n",
    "$$ \\Large \\int\\limits_a^b f(x) dx \\approx \\frac{b-a}{N} \\sum\\limits_{i=1}^N f(x_i) $$\n",
    "\n",
    "or in $k$ dimensions, a sum over the whole volume $V$ of the multi-dimensional parameter space $\\Omega$:\n",
    "\n",
    "$$ \\Large \\int_\\Omega f(\\vec{x}) d\\vec{x} \\approx \\frac{V}{N} \\sum\\limits_{i=1}^N f(\\vec{x}_i)$$\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Tasks:**\n",
    "    \n",
    "1. Choose a sample size for the Monte Carlo calculation.\n",
    "2. Calculate the Bayes factor.\n",
    "3. Which model is preferred? Does this agree with AIC and BIC?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ...\n",
    "amp_samples = np.random.uniform(MIN_AMPLITUDE, MAX_AMPLITUDE, size=sample_size)\n",
    "loc_samples = np.random.uniform(MIN_LOCATION, MAX_LOCATION, size=sample_size)\n",
    "wid_samples = np.random.uniform(MIN_WIDTH, MAX_WIDTH, size=sample_size)\n",
    "\n",
    "# use no normalization factor (watch out for the NaNs)\n",
    "ln_norm_factor = 0.0\n",
    "print(\"Normalization factor:\", ln_norm_factor)\n",
    "\n",
    "sum_norm = 0.0\n",
    "sum_cauchy = 0.0\n",
    "\n",
    "for amp, loc, wid in zip(amp_samples, loc_samples, wid_samples):\n",
    "    sum_norm += ...\n",
    "    sum_cauchy += ...\n",
    "    \n",
    "K = sum_norm / sum_cauchy\n",
    "print(f\"K (norm / cauchy): {K:.4g}\")\n",
    "print(f\"K (cauchy / norm): {1.0/K:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ae9a3",
   "metadata": {},
   "source": [
    "### Warning: Numerical precision & machine $\\epsilon$ (`eps`)\n",
    "\n",
    "1. Probabilities (or their densities) can be very small numbers, especially when calculated away from the maxima. \n",
    "2. Likelihoods (and hence priors) can be even smaller if we have large datasets (because probabilities are multiplied). \n",
    "\n",
    "**Example**\n",
    "It's not unconceivable to have log-likelihood values $\\ln L_i \\approx -10000$. If we need to do operations in the linear space, e.g., $L_i \\approx e^{-10000}$ we will end up with a bunch of zeros due to the limited exponent range of floating-point numbers.\n",
    "\n",
    "**Solution**: We can use a normalization factor that brings these numbers closer to 1. ***We need to be sure that we use the same factor accross all evaluations of the likelihoods/posteriors, and all models if we perform model comparisons***. This normalization factor can be the first number we obtain in our calculations,\n",
    "$$\\large L_i = L_1 \\frac{L_i}{L_1} \\propto e^{\\ln L_i - \\ln L_1} $$,\n",
    "or perhaps the mean, or median, or minimum/maximum value we encountered (however this requires to save all values),\n",
    "$$\\large L_i \\propto e^{\\ln L_i - \\max \\{\\ln L_i\\}} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AstroStat24)",
   "language": "python",
   "name": "astrostat24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
